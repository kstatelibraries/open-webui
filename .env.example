# Set ollama url's for load balancing requests separated by ";"
OLLAMA_BASE_URLS='http://host.docker.internal:12000'

# Webui general settings
WEBUI_SECRET_KEY=''
WEBUI_NAME='KSUL GPT'

# Set user authentication required
WEBUI_AUTH=false

# Set default available models to users
DEFAULT_MODELS='llama3.2'

# Disables all "Functions"
SAFE_MODE=true

# DO NOT TRACK --- no docs say these are used...but lets be safe
SCARF_NO_ANALYTICS=true
DO_NOT_TRACK=true
ANONYMIZED_TELEMETRY=false